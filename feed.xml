<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://zj-gao.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zj-gao.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-04T22:53:41+00:00</updated><id>https://zj-gao.github.io/feed.xml</id><title type="html">ZJ Gao’s Research Site</title><subtitle>Zijie Gao&apos;s Personal Website Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Python Template for Plotting Kernel Density Estimates (KDE) of Detrital Zircon U-Pb Data</title><link href="https://zj-gao.github.io/blog/2024/Detrital-Zircon-KDE/" rel="alternate" type="text/html" title="Python Template for Plotting Kernel Density Estimates (KDE) of Detrital Zircon U-Pb Data"/><published>2024-11-07T00:00:00+00:00</published><updated>2024-11-07T00:00:00+00:00</updated><id>https://zj-gao.github.io/blog/2024/Detrital-Zircon-KDE</id><content type="html" xml:base="https://zj-gao.github.io/blog/2024/Detrital-Zircon-KDE/"><![CDATA[<h1 id="motivation">Motivation</h1> <p>Being part of a group well-known for applying U-Pb dating on detrital zircons to study sediment routing, my research methods are typically expected to focus on core description, statistical analysis, and luminescence dating. Initially, I assumed that U-Pb data wouldn’t be a major part of my work, as the samples are either from the Ganges or Brahmaputra rivers. However, when examining super sandy, thick sediment gravity flow deposits (most of which are turbidites), the lithofacies of these deposits surprisingly resemble features typical of the Brahmaputra.</p> <p>This resemblance raises an interesting hypothesis: Could triggering events have occurred upstream in the Brahmaputra River, under favorable external conditions (such as climate-controlled low sea levels), to produce what we now observe as megaturbidites at the distal edge of the Bengal Fan, where our core samples were collected?</p> <h2 id="developing-a-python-based-kde-plotting-tool">Developing a Python-Based KDE Plotting Tool</h2> <p>While there are great tools available for sedimentology data analysis, they are largely based on MATLAB or R. Although I have some familiarity with MATLAB, Python remains my tool of choice. To avoid switching programming environments, I decided to create my own Kernel Density Estimation (KDE) plotting functions in Python. I wanted these plots to meet publication standards, so I used visualization styles from my advisor Mike Blum’s 2018 paper as a reference. <em>(See the paper <a href="https://www.nature.com/articles/s41598-018-25819-5">here</a>).</em> The sample data I’m displaying here is also from that paper, but we’re in the process of collecting new data for future publications!</p> <h2 id="setting-up-the-data">Setting Up the Data</h2> <p>To get started, you’ll need an Excel workbook for your data. If you plan to plot data from multiple sampling sites, arrange the age data from each site in a separate column, with each column named after the sampling site.</p> <h2 id="building-a-basic-plot">Building a Basic Plot</h2> <p>We’ll start with a very simple plot. Initially, I set the bandwidth hyperparameter to 0.01. This creates a trend that appears somewhat bumpy, so I added a smoothing function to improve the visual appeal. The goal is to use the script below to experiment with both the bandwidth and smoothing factors, finding an optimal balance. Decreasing the bandwidth provides more detail, but can result in a bumpy appearance, where smoothing can help make the plot more visually pleasing while retaining the key features of the data.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/KDE/crude_plot-480.webp 480w,/assets/img/posts/KDE/crude_plot-800.webp 800w,/assets/img/posts/KDE/crude_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/KDE/crude_plot.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Below is a sample script to begin working with and the image is a preview of how the interface looks like. Feel free to adjust the parameters as needed:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/KDE/interactive_plot-480.webp 480w,/assets/img/posts/KDE/interactive_plot-800.webp 800w,/assets/img/posts/KDE/interactive_plot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/KDE/interactive_plot.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>
<span class="kn">from</span> <span class="n">scipy.ndimage</span> <span class="kn">import</span> <span class="n">gaussian_filter1d</span>
<span class="kn">from</span> <span class="n">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">widgets</span>

<span class="k">def</span> <span class="nf">plot_kde</span><span class="p">(</span><span class="n">data_sample</span><span class="p">,</span> <span class="n">bandwidth</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="c1"># Generate KDE
</span>    <span class="n">kde</span> <span class="o">=</span> <span class="nf">gaussian_kde</span><span class="p">(</span><span class="n">data_sample</span><span class="p">,</span> <span class="n">bw_method</span><span class="o">=</span><span class="n">bandwidth</span><span class="p">)</span>
    <span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">y_values</span> <span class="o">=</span> <span class="nf">kde</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span>
    
    <span class="c1"># Apply smoothing filter
</span>    <span class="n">y_smooth</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">y_values</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    
    <span class="c1"># Plotting
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">))</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_smooth</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Age (Ma)</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Normalized KDE</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># Set x-axis limits and major ticks
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3500</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3501</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>  <span class="c1"># Major ticks every 500
</span>    
    <span class="c1"># Add minor ticks every 100
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">xaxis</span><span class="p">.</span><span class="nf">set_minor_locator</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="nc">MultipleLocator</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
    
    <span class="c1"># Customize minor tick appearance
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="sh">'</span><span class="s">minor</span><span class="sh">'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># Remove y-axis ticks
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_ticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_ticklabels</span><span class="p">([])</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Create interactive sliders for bandwidth and sigma, and add data_sample as a fixed argument
</span><span class="k">def</span> <span class="nf">interactive_plot</span><span class="p">(</span><span class="n">data_sample</span><span class="p">):</span>
    <span class="nf">interact</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">bandwidth</span><span class="p">,</span> <span class="n">sigma</span><span class="p">:</span> <span class="nf">plot_kde</span><span class="p">(</span><span class="n">data_sample</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="n">bandwidth</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">),</span>
        <span class="n">bandwidth</span><span class="o">=</span><span class="n">widgets</span><span class="p">.</span><span class="nc">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">0.008</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
                                      <span class="n">description</span><span class="o">=</span><span class="sh">'</span><span class="s">Bandwidth</span><span class="sh">'</span><span class="p">,</span> <span class="n">readout_format</span><span class="o">=</span><span class="sh">'</span><span class="s">.3f</span><span class="sh">'</span><span class="p">),</span>
        <span class="n">sigma</span><span class="o">=</span><span class="n">widgets</span><span class="p">.</span><span class="nc">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="sh">'</span><span class="s">Smooth</span><span class="sh">'</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></div> <h1 id="stacked-kde-plots-of-multiple-samples">Stacked KDE Plots of Multiple Samples</h1> <h2 id="simple-stack">Simple Stack</h2> <p>When plotting stacked KDEs of multiple samples, the script will automatically use the column names and sample sizes as labels for each plot. The stacking order follows the sequence of columns in the Excel file, meaning the first column will be plotted at the bottom.</p> <p>The <code class="language-plaintext highlighter-rouge">para_dict</code> is a dictionary where each key corresponds to a sample name, and the values are: 1) the age data, 2) the bandwidth parameter, and 3) the smoothing factor. After experimenting with one sample to determine a comfortable combination of bandwidth and smoothing factor, I found that my samples could share the same values, so I set a <code class="language-plaintext highlighter-rouge">default_bandwidth</code> and <code class="language-plaintext highlighter-rouge">default_smooth_factor</code> based on this. For cases where samples may require different settings, I recommend updating the <code class="language-plaintext highlighter-rouge">para_dict</code> accordingly to fine-tune each sample’s parameters.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">"""</span><span class="s">
    Import Data with defaulted bandwidth and smooth factor
</span><span class="sh">"""</span>
<span class="c1"># Load the Excel file
</span><span class="n">excel_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Blum_2018_Bengal_Fan.xlsx</span><span class="sh">"</span>  <span class="c1"># Replace with the actual path to your file and put it under the same directory of the script
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span><span class="n">excel_path</span><span class="p">)</span>

<span class="c1"># Default values for bandwidth and smooth factor
</span><span class="n">default_bandwidth</span> <span class="o">=</span> <span class="mf">0.008</span>
<span class="n">default_smooth_factor</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># Initialize the param_dict
</span><span class="n">param_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Process each column to construct the dictionary with column name and valid data count
</span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Count the number of non-NaN values in the column
</span>    <span class="n">valid_data_count</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="nf">count</span><span class="p">()</span>
    <span class="c1"># Construct the key with column name and valid data count
</span>    <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s"> (n=</span><span class="si">{</span><span class="n">valid_data_count</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span>
    <span class="c1"># Assign the column data to the dictionary, excluding NaN values, along with default parameters
</span>    <span class="n">param_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="nf">dropna</span><span class="p">().</span><span class="n">values</span><span class="p">,</span> <span class="n">default_bandwidth</span><span class="p">,</span> <span class="n">default_smooth_factor</span><span class="p">]</span>

<span class="nf">print</span><span class="p">(</span><span class="n">param_dict</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>
</code></pre></div></div> <p>Define the visualization function</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>
<span class="kn">from</span> <span class="n">scipy.ndimage</span> <span class="kn">import</span> <span class="n">gaussian_filter1d</span>

<span class="k">def</span> <span class="nf">plot_stacked_kdes</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">color_blocks</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># Create figure
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Add color blocks if provided
</span>    <span class="k">if</span> <span class="n">color_blocks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="n">color_blocks</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">axvspan</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>  <span class="c1"># Alpha for transparency
</span>
    <span class="c1"># Loop through each dataset and plot
</span>    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bandwidth</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="p">))</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">params</span><span class="p">.</span><span class="nf">items</span><span class="p">()):</span>
        <span class="c1"># Clean data by removing NaNs and infinities
</span>        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">data</span><span class="p">)]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">isfinite</span><span class="p">(</span><span class="n">data</span><span class="p">)]</span>

        <span class="c1"># Generate KDE
</span>        <span class="n">kde</span> <span class="o">=</span> <span class="nf">gaussian_kde</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bw_method</span><span class="o">=</span><span class="n">bandwidth</span><span class="p">)</span>
        <span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>  <span class="c1"># x-axis range and resolution
</span>        <span class="n">y_values</span> <span class="o">=</span> <span class="nf">kde</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span>

        <span class="c1"># Apply smoothing filter
</span>        <span class="n">y_smooth</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">y_values</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">smooth_factor</span><span class="p">)</span>

        <span class="c1"># Normalize each curve to have a maximum height of 1
</span>        <span class="n">y_smooth</span> <span class="o">=</span> <span class="n">y_smooth</span> <span class="o">/</span> <span class="nf">max</span><span class="p">(</span><span class="n">y_smooth</span><span class="p">)</span>

        <span class="c1"># Offset the y-values to separate curves
</span>        <span class="n">y_offset</span> <span class="o">=</span> <span class="n">y_smooth</span> <span class="o">+</span> <span class="n">idx</span> <span class="o">*</span> <span class="n">offset</span>

        <span class="c1"># Plot the smoothed KDE with black color and line width of 1
</span>        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_offset</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Add text label aligned to the right end of the plot, slightly above the curve
</span>        <span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">3500</span><span class="p">,</span> <span class="n">y_offset</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">offset</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> 
                 <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Customize the x-axis
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3500</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Age (Ma)</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    
    <span class="c1"># Add major ticks every 500 and minor ticks every 100 on the x-axis
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3501</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>  <span class="c1"># Major ticks every 500
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">xaxis</span><span class="p">.</span><span class="nf">set_minor_locator</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="nc">MultipleLocator</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>

    <span class="c1"># Thicken x-axis spine and customize x-axis tick appearance
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">spines</span><span class="p">[</span><span class="sh">'</span><span class="s">bottom</span><span class="sh">'</span><span class="p">].</span><span class="nf">set_linewidth</span><span class="p">(</span><span class="mf">1.5</span><span class="p">)</span>  <span class="c1"># Thicker x-axis spine
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Thicker x-axis major ticks and labels
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="sh">'</span><span class="s">minor</span><span class="sh">'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>  <span class="c1"># Thicker minor ticks
</span>
    <span class="c1"># Remove y-axis ticks and labels for a clean stacked look
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_ticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_ticklabels</span><span class="p">([])</span>

    <span class="c1"># Remove only the top and right spines, keep the bottom (x-axis) spine
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">spines</span><span class="p">[</span><span class="sh">'</span><span class="s">top</span><span class="sh">'</span><span class="p">].</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">spines</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">].</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="n">spines</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">].</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <p>Run the following command to generate a simple stack graph. <code class="language-plaintext highlighter-rouge">offset</code> defines the vertical distance between each KDE plot.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_stacked_kdes</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">param_dict</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">color_blocks</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/KDE/plain%20stack-480.webp 480w,/assets/img/posts/KDE/plain%20stack-800.webp 800w,/assets/img/posts/KDE/plain%20stack-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/KDE/plain%20stack.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="stacked-plot-with-densely-populated-age-groups-noted-in-different-colors">Stacked Plot with densely populated age groups noted in different colors</h2> <p>These are preliminary age groups in the Bengal Fan dataset, observed visually (and therefore approximate), to create a demo visualization. Accurate ages, supported by literature, will be included in future updates.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">color_blocks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="p">(</span><span class="mi">173</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">217</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">152</span><span class="o">/</span><span class="mi">255</span><span class="p">)),</span>   <span class="c1"># Greenish block (A)
</span>    <span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="p">(</span><span class="mi">140</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">200</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">225</span><span class="o">/</span><span class="mi">255</span><span class="p">)),</span> <span class="c1"># Light Blue block (B)
</span>    <span class="p">(</span><span class="mi">700</span><span class="p">,</span> <span class="mi">900</span><span class="p">,</span> <span class="p">(</span><span class="mi">158</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">185</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">225</span><span class="o">/</span><span class="mi">255</span><span class="p">)),</span> <span class="c1"># Blue block (C)
</span>    <span class="p">(</span><span class="mi">910</span><span class="p">,</span> <span class="mi">1250</span><span class="p">,</span> <span class="p">(</span><span class="mi">245</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">220</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">200</span><span class="o">/</span><span class="mi">255</span><span class="p">)),</span> <span class="c1"># Adjusted Light Orange block (D)
</span>    <span class="p">(</span><span class="mi">1300</span><span class="p">,</span> <span class="mi">1700</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">205</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">185</span><span class="o">/</span><span class="mi">255</span><span class="p">)),</span> <span class="c1"># Adjusted Light Pink block (E)
</span>    <span class="p">(</span><span class="mi">1710</span><span class="p">,</span> <span class="mi">2100</span><span class="p">,</span> <span class="p">(</span><span class="mi">245</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">190</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">150</span><span class="o">/</span><span class="mi">255</span><span class="p">)),</span> <span class="c1"># Orange block (F)
</span>    <span class="p">(</span><span class="mi">2300</span><span class="p">,</span> <span class="mi">2750</span><span class="p">,</span> <span class="p">(</span><span class="mi">235</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">140</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="mi">135</span><span class="o">/</span><span class="mi">255</span><span class="p">))</span>  <span class="c1"># Red block (G)
</span><span class="p">]</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/KDE/Color_Block_Notation-480.webp 480w,/assets/img/posts/KDE/Color_Block_Notation-800.webp 800w,/assets/img/posts/KDE/Color_Block_Notation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/KDE/Color_Block_Notation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_stacked_kdes</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">param_dict</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">color_blocks</span><span class="o">=</span><span class="n">color_blocks</span><span class="p">)</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/KDE/color%20stack-480.webp 480w,/assets/img/posts/KDE/color%20stack-800.webp 800w,/assets/img/posts/KDE/color%20stack-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/KDE/color%20stack.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Here’s the link to the script you can run in Jupyter Notebook: <a href="https://github.com/ZJ-Gao/Detrital_Zircon_KDE_Plot/blob/main/KDE.ipynb">KDE Plot Script on GitHub</a>.</p>]]></content><author><name></name></author><category term="Data-Science"/><category term="DataScience"/><category term="Detrital_Zircon"/><category term="U-Pb"/><category term="Dating"/><category term="KDE"/><summary type="html"><![CDATA[Interactive bar available to best present your data]]></summary></entry><entry><title type="html">Semi-Automated Elemental Data Extraction from EDX Reports Using Python and ChatGPT</title><link href="https://zj-gao.github.io/blog/2024/XRD/" rel="alternate" type="text/html" title="Semi-Automated Elemental Data Extraction from EDX Reports Using Python and ChatGPT"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://zj-gao.github.io/blog/2024/XRD</id><content type="html" xml:base="https://zj-gao.github.io/blog/2024/XRD/"><![CDATA[<p><strong>Comment 10/4/2024</strong></p> <p> I strongly suspect that the parameters in the ChatGPT model are still changing somehow. The same prompt yields different results even in the same conversation that ever generated perfect results. I also suspect they restrict easy access to the higher-performance OCR model unless you specifically push for it. If you use the prompt I suggested but don’t get the ideal result, start with a single image. Ask it to output the OCR result and then move on to multiple images, and then compile the result into a table. And always, check each image. It already saves you the time and effort of manually logging in, so it's worth spending time to ensure the results are accurate. </p> <p>—————————————–Below is the old Blog—————————————–</p> <p> Do you find logging elemental percentage data from a generated report to be time-consuming? Here's a quick solution, as long as you're familiar with basic Python and ChatGPT prompts: </p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/XRD-480.webp 480w,/assets/img/posts/XRD-800.webp 800w,/assets/img/posts/XRD-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/XRD.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ol> <li><strong>Save all the images from the EDX report</strong> using this script: <a href="https://github.com/ZJ-Gao/OCR_XRD_Reports/blob/main/save_imgs_in_MSword.ipynb"><code class="language-plaintext highlighter-rouge">save_imgs_in_MSword.ipynb</code></a>. Or you can copy from the code snippet at the bottom of this blog. The images will be automatically numbered and saved in the same directory as the report.</li> <li><strong>Remove unnecessary images</strong>: If the report contains images that are not EDX graphs, you can manually delete them.</li> <li><strong>Use the ChatGPT-4 model</strong>: People are cautious about using ChatGPT, fearing it might provide fabricated answers. It’s true, this can happen at times. However, when it comes to OCR usage in EDX reports, I tested it for you. Using the prompts below, the results are reliable. This model has a robust embedded vision system that works well for OCR tasks. I tested several Python OCR libraries, even with data enhancement techniques, but none achieved satisfactory results. If you’re aware of any high-performance open-source OCR models, please share them!</li> <li> <p><strong>Use the following prompt in ChatGPT</strong>:</p> <p><em>For all the images I upload, extract the information from the legend and create a table. The first column should be “Spectrum,” and the subsequent columns should represent elemental information (O, Si, K, Al, Na) and their respective weight percentages (Wt%). Exclude the standard deviation (σ).</em></p> </li> <li><strong>Download the extracted data</strong>: ChatGPT will provide a table with the extracted data, which you can download as a CSV file.</li> <li><strong>Verify the results</strong>: Randomly select a few graphs to check the accuracy of the data extraction by ChatGPT-4.</li> </ol> <h3 id="notes">Notes:</h3> <ul> <li>In ChatGPT, you can upload up to 10 images at a time and are subject to a daily upload limit. This process works well for small tasks.</li> <li>However, for larger datasets (like mine), I’m looking for a solution that can handle batch processing locally. If you have any suggestions or ideas, feel free to reach out!</li> </ul> <h3 id="grab-the-codes">Grab the codes</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">docx</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="n">io</span>

<span class="c1"># Load the Word document
</span><span class="n">doc_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Camp Century Hawke_USU-4183B 250-355 Points.docx</span><span class="sh">'</span>  <span class="c1"># Update with your document path
</span><span class="n">doc</span> <span class="o">=</span> <span class="nc">Document</span><span class="p">(</span><span class="n">doc_path</span><span class="p">)</span>

<span class="c1"># Iterate through the document and save images
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rel</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">doc</span><span class="p">.</span><span class="n">part</span><span class="p">.</span><span class="n">rels</span><span class="p">.</span><span class="nf">values</span><span class="p">()):</span>
    <span class="k">if</span> <span class="sh">"</span><span class="s">image</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">rel</span><span class="p">.</span><span class="n">target_ref</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">rel</span><span class="p">.</span><span class="n">target_part</span><span class="p">.</span><span class="n">blob</span>
        <span class="n">image_stream</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nc">BytesIO</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">image_stream</span><span class="p">)</span>
        <span class="n">img</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">image_</span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">.png</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Save images as PNG files
</span>
<span class="c1"># Note: Update the file extension as needed based on the image type
</span></code></pre></div></div>]]></content><author><name></name></author><category term="Data-Science"/><category term="DataScience"/><category term="Chatgpt"/><category term="Automation"/><summary type="html"><![CDATA[Comment 10/4/2024 I strongly suspect that the parameters in the ChatGPT model are still changing somehow. The same prompt yields different results even in the same conversation that ever generated perfect results. I also suspect they restrict easy access to the higher-performance OCR model unless you specifically push for it. If you use the prompt I suggested but don’t get the ideal result, start with a single image. Ask it to output the OCR result and then move on to multiple images, and then compile the result into a table. And always, check each image. It already saves you the time and effort of manually logging in, so it's worth spending time to ensure the results are accurate.]]></summary></entry><entry><title type="html">How to use statistical knowledge when analyzing geological data?</title><link href="https://zj-gao.github.io/blog/2024/MLE/" rel="alternate" type="text/html" title="How to use statistical knowledge when analyzing geological data?"/><published>2024-08-13T00:00:00+00:00</published><updated>2024-08-13T00:00:00+00:00</updated><id>https://zj-gao.github.io/blog/2024/MLE</id><content type="html" xml:base="https://zj-gao.github.io/blog/2024/MLE/"><![CDATA[<p>We often learn pure math and statistical concepts in class, encountering jargon like <strong>mean</strong>, <strong>median</strong>, <strong>mode</strong>, <strong>standard deviation</strong>, <strong>variance</strong>, and even more complex terms like <strong>PDF</strong> (Probability Density Function) and <strong>CDF</strong> (Cumulative Distribution Function). Understanding the statistics and the math behind these concepts, which means building a logic linkage between the math, the physical shape of the data distribution, and the statistical meaning behind it is already challenging.</p> <p>When it comes to real life, dealing with our own geological data, it seems we are disconnected from what we learnt from the statistical class. Here I’m going to use my study case as an example to show how I proceed to tie my statistic knowledge and the information I want to read from my data together. The background is that numerous sandy deep-water deposits were recovered by IODP 354, a drilling program in the distal Bengal Fan. I’m curious to know about how thick are these events and how many are they. A histogram is a good way of visualization to inform me the facts I’m about to know. When I try to analyze my data, I don’t necessarily have all that statistical knowledge in the forefront of my mind. Instead, I’m more driven by the geological question I want to answer:</p> <ul> <li>What are the most frequently occurring thicknesses?</li> <li>What about the super thick ones?</li> <li>Will they tail down at the end, or do they represent a peak on their own?</li> </ul> <p>I first plotted a histogram under a linear scale, but there wasn’t much information to be gleaned from it. Due to my past experience, I knew that geological data often benefits from being plotted on a logarithmic scale, so I tried that as well. After a few attempts at adjusting the bin numbers, the histogram finally looked both informative and aesthetically pleasing.</p> <h3 id="observations-from-the-data"><strong>Observations from the Data</strong></h3> <p>As I began my observations (The final graph plotted with my data will be attached here once it is published. For now, the graph’s shape is similar to the thumbnail image when you clicked the post):</p> <ul> <li>The distribution looked skewed to the left.</li> <li>The most frequently occurring thicknesses seemed to be those between 10 cm and 20 cm.</li> <li>However, I noticed that if I changed the bin number, the exact range of the most frequent group would slightly shift.</li> <li>Additionally, I observed that the super thick events, those over 100 cm, were situated at the right tail of the distribution.</li> </ul> <p>These are good observations, based on intuition, but to ensure that the information is consistently conveyed to others, we need to quantify our observations. After all, different people may have different definitions for what qualifies as “super thick,” a term not globally defined.</p> <h3 id="introducing-statistical-concepts"><strong>Introducing Statistical Concepts</strong></h3> <p>This is where statistical knowledge becomes invaluable. The bin number is a parameter you can adjust to better visualize the data—it’s flexible and helps you see different aspects of the dataset. However, the <strong>descriptive statistics</strong> are fixed; they are inherent properties of the dataset.</p> <ul> <li><strong>Mode</strong>: The mode is the parameter used to describe the most frequently occurring value. It can be calculated as the value that appears most often in the dataset.</li> <li><strong>Outliers</strong>: The super thick sediment gravity flows (SGFs) at the tail are outliers. To define outliers formally, one common method is using <strong>mean + 2\(\sigma\) (standard deviations)</strong>. In this case, for our data, this threshold is around 2 meters. Rather than calling these events “super thick,” we define them as <strong>outsized</strong> to make the term more formal.</li> </ul> <h3 id="understanding-the-empirical-rule"><strong>Understanding the Empirical Rule</strong></h3> <p>One thing to keep in mind is the <strong>empirical rule</strong>, also known as the 68-95-99.7 rule. This rule states that:</p> <ul> <li>68% of the data falls within one standard deviation of the mean,</li> <li>95% falls within two standard deviations,</li> <li>99.7% falls within three standard deviations.</li> </ul> <p>However, this rule is derived from a <strong>symmetric normal distribution</strong> and does not apply to skewed data, like the left-skewed distribution we’re dealing with here.</p> <h3 id="quantifying-the-observations"><strong>Quantifying the Observations</strong></h3> <p>Now, with these quantifying ideas in mind, let’s revisit the graph. We still use descriptive terms like <strong>left-skewed lognormal distribution</strong>, but now we supplement these with numbers, like the mode and the threshold for outliers. What if we want to delve deeper, or just say we want to be a little more nerdier mathematically as a geologist:</p> <ul> <li><strong>Fitting a Distribution</strong>: How can we use a solid equation to fit this distribution?</li> <li><strong>Calculating Probabilities</strong>: What’s the probability of forming these outsized SGFs?</li> </ul> <h3 id="fitting-the-lognormal-distribution"><strong>Fitting the Lognormal Distribution</strong></h3> <p>We’ve already determined that the distribution pattern we’re dealing with is a <strong>lognormal distribution</strong>. The general equation for the PDF of a lognormal distribution is:</p> \[f(x) = \frac{1}{x\sigma\sqrt{2\pi}} \exp\left(-\frac{(\ln(x) - \mu)^2}{2\sigma^2}\right)\] <p>Where:</p> <ul> <li>\(x\) is the thickness,</li> <li>\(\mu\) is the mean of the log-transformed data,</li> <li>\(\sigma\) is the standard deviation of the log-transformed data.</li> </ul> <h3 id="customizing-the-distribution-using-maximum-likelihood-estimation-mle"><strong>Customizing the Distribution Using Maximum Likelihood Estimation (MLE)</strong></h3> <p>To apply the lognormal distribution equation to our data, we need to <strong>personalize</strong> it by estimating the parameters \(\mu\) and \(\sigma\) using the <strong>method of Maximum Likelihood Estimation (MLE)</strong>. Here’s how you can execute MLE with logarithms base 10:</p> <ol> <li><strong>Log-transform the data (using log base 10)</strong>: <ul> <li>First, transform your thickness data by taking the logarithm base 10 of each data point, resulting in a new dataset \(\log_{10}(x)\).</li> </ul> </li> <li><strong>Write the likelihood function</strong>: <ul> <li>The likelihood function is the <strong>product of the PDF</strong> for each data point in your sample because this is how you <strong>mathematically combine independent observations</strong> to reflect <strong>the overall likelihood of the entire dataset</strong>. In essence, it aggregates the information from all the individual data points to provide a <strong>comprehensive measure</strong> of how likely the observed data is under the given distribution parameters.</li> <li>The likelihood function represents the probability of observing your data given specific values of the parameters \(\mu\) and \(\sigma\). For a lognormal distribution with base 10 logarithms, the likelihood function \(L(\mu, \sigma)\) based on the transformed data can be written as:</li> </ul> \[L(\mu, \sigma) = \prod_{i=1}^{n} \frac{1}{x_i \sigma \sqrt{2\pi}} \exp \left( -\frac{(\log_{10}(x_i) - \mu)^2}{2\sigma^2} \right)\] </li> <li><strong>Derive the log-likelihood function</strong>: <ul> <li>To simplify the likelihood function, take the logarithm base 10 of the likelihood function, which converts the product into a sum. This gives you the <strong>log-likelihood function</strong>:</li> </ul> \[\log_{10}(L(\mu, \sigma)) = -\frac{n}{2} \log_{10}(2\pi) - n \log_{10}(\sigma) - \sum_{i=1}^{n} \log_{10}(x_i) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (\log_{10}(x_i) - \mu)^2\] </li> <li> <p><strong>Differentiate the log-likelihood function</strong>:</p> <p>The next step is to maximize the log-likelihood function with respect to \(\mu\) and \(\sigma\) to find the values that make the observed data most probable. The essence is to calculate the derivatives of the \(\log_{10}(L(\mu, \sigma))\) with respect to \(\mu\) and \(\sigma\), and find the maximum likelihood estimates for these parameters.</p> <p>To find the maximum likelihood estimates for \(\mu\) and \(\sigma\), we differentiate the log-likelihood function with respect to each parameter.</p> <ul> <li><strong>For</strong> \(\mu\): Differentiate the log-likelihood function with respect to \(\mu\):</li> </ul> \[\frac{\partial \log_{10}(L(\mu, \sigma))}{\partial \mu} = \frac{1}{\sigma^2} \sum_{i=1}^{n} (\log_{10}(x_i) - \mu)\] <ul> <li><strong>For</strong> \(\sigma\): Differentiate the log-likelihood function with respect to \(\sigma\):</li> </ul> \[\frac{\partial \log_{10}(L(\mu, \sigma))}{\partial \sigma} = -\frac{n}{\sigma \ln(10)} + \frac{1}{\sigma^3 \ln(10)} \sum_{i=1}^{n} (\log_{10}(x_i) - \mu)^2\] </li> <li> <p><strong>Set the derivatives to zero to find the maximum</strong>:</p> <p>To find the maximum of the log-likelihood function, set the partial derivatives with respect to \(\mu\) and \(\sigma\) equal to zero:</p> <ul> <li><strong>For</strong> \(\mu\):</li> </ul> \[\frac{\partial \log_{10}(L(\mu, \sigma))}{\partial \mu} = 0 \implies \sum_{i=1}^{n} (\log_{10}(x_i) - \mu) = 0\] <p>This equation simplifies to:</p> \[\mu = \frac{1}{n} \sum_{i=1}^{n} \log_{10}(x_i)\] <p>After applying the dataset, each thickness data point corresponds to \(x_i\). \(\mu\) will be obtained, which is the mean of the log-transformed data.</p> <p>The same workflow applies for obtaining \(\sigma\).</p> <ul> <li><strong>For</strong> \(\sigma\):</li> </ul> \[\frac{\partial \log_{10}(L(\mu, \sigma))}{\partial \sigma} = 0 \implies -\frac{n}{\sigma \ln(10)} + \frac{1}{\sigma^3 \ln(10)} \sum_{i=1}^{n} (\log_{10}(x_i) - \mu)^2 = 0\] <p>This equation simplifies to:</p> \[\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (\log_{10}(x_i) - \mu)^2\] <p>\(\sigma\) can then be calculated after applying the dataset, which is the standard deviation of the log-transformed data.</p> <p>So far, the values of \(\mu\) and \(\sigma\) that maximize the log-likelihood function are your MLE estimates. These estimates will be used to define your personalized lognormal distribution, and to construct the probability density function (PDF) and cumulative distribution function (CDF) specific to your data, enabling further analysis and interpretation.</p> <p>In high school, teachers just teach you the equation for calculating \(\mu\) and \(\sigma\), and let you memorize them for exams. Now packages in Python like <code class="language-plaintext highlighter-rouge">pandas</code> can give you all the descriptive stats with just one line of code:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">df</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div> </div> <p>But if you take the time to work through these calculations yourself, it really helps you understand why we’re doing them and what they actually mean. Plus, there’s a sense of accomplishment when your calculated results align with what you learned from your high school teacher. We are standing on the shoulders of giants.</p> </li> </ol> <h3 id="calculating-the-cumulative-distribution-function-cdf"><strong>Calculating the Cumulative Distribution Function (CDF)</strong></h3> <p>Once we have the equation for the PDF, we can calculate the <strong>Cumulative Distribution Function (CDF)</strong>, which represents the accumulating probability, by integrating the PDF:</p> \[F(x) = \int_{-\infty}^{x} f(t) \, dt\] \[F(x) = P(X \leq x) = \Phi\left(\frac{\log_{10}(x) - \mu}{\sigma}\right)\] <p>This CDF will give us the cumulative probability up to a certain thickness.</p> <h3 id="determining-the-probability-of-outsized-sgfs"><strong>Determining the Probability of Outsized SGFs</strong></h3> <p>To calculate the probability of forming outsized SGFs with thicknesses between 2m and 10m, we follow these steps:</p> <ol> <li><strong>Calculate the CDF for 2m and 10m</strong>: Find the CDF values for these thicknesses using the personalized lognormal distribution.</li> <li><strong>Subtract the CDF values</strong>: Subtract the CDF value at 2m from the CDF value at 10m to get the probability of a thickness falling within this range.</li> </ol> <h3 id="conclusion"><strong>Conclusion</strong></h3> <p>In this blog, we’ve explored how statistical tools can be applied to geological data, making those initially confusing statistical terms our allies. With these quantified observations and a clear understanding of their statistical meaning, we can confidently move forward with our geological interpretations, using data to back up our insights.</p>]]></content><author><name></name></author><category term="Data-Science"/><category term="DataScience"/><category term="Math"/><category term="Statistics"/><summary type="html"><![CDATA[Bridging the Gap Between Statistics and Geological Data\(:\) A Little Case Using Histogram. Will update with data and graphs once published!]]></summary></entry></feed>